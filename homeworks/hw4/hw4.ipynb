{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Simulation, Sampling, and Bootstrapping\n",
    "\n",
    "## Due Saturday, November 8th at 11:59PM\n",
    "\n",
    "Welcome to Homework 4! This homework will cover:\n",
    "- Simulations (see [CIT 9.3-9.4](https://inferentialthinking.com/chapters/09/3/Simulation.html))\n",
    "- Sampling and Empirical Distributions (see [CIT 10-10.4](https://inferentialthinking.com/chapters/10/Sampling_and_Empirical_Distributions.html))\n",
    "- Bootstrapping and Confidence Intervals (see [CIT 13.2](https://inferentialthinking.com/chapters/13/2/Bootstrap.html) and [CIT 13.3](https://inferentialthinking.com/chapters/13/3/Confidence_Intervals.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Remember to start early and submit often. You are given six slip days throughout the quarter to extend deadlines. See the syllabus for more details. With the exception of using slip days, late work will not be accepted unless you have made special arrangements with your instructor.\n",
    "\n",
    "**Important**: For homeworks, the `otter` tests don't usually tell you that your answer is correct. More often, they help catch careless mistakes. It's up to you to ensure that your answer is correct. If you're not sure, ask someone (not for the answer, but for some guidance about your approach). These are great questions for office hours (the schedule can be found [here](https://dsc10.com/calendar)) or Campuswire. Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell, but do make sure to run it.\n",
    "import babypandas as bpd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-colorblind')\n",
    "\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lucky Triton Lotto, Continued  🔱 🎱 🧜\n",
    "\n",
    "In the last homework, we calculated the probability of winning the grand prize (free housing) on a Lucky Triton Lotto lottery ticket, and found that it was quite low 😭."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, do not change it!\n",
    "free_housing_chance = (1 / 29) * (1 / 28) * (1 / 27) * (1 / 26) * (1 / 25) * (1 / 12)\n",
    "free_housing_chance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question, we'll approach the same question not using math, but using simulation. \n",
    "\n",
    "It's important to remember how this lottery works:\n",
    "\n",
    "- First, you pick five **different** numbers, one at a time, from 1 to 29, representing that according to [USNews](https://www.usnews.com/best-colleges/university-of-california-san-diego-1317#:~:text=based%20academic%20calendar.-,University%20of%20California%2C%20San%20Diego's%20ranking%20in%20the%202022%2D2023,Jolla%20community%20of%20San%20Diego.), UCSD is ranked 29 in the nation for best universities to attend for 2025-2026.\n",
    "- Then, you separately pick a number from 1 to 8. This is because UCSD's Data Science program is rank 8th in [USNews's](https://www.usnews.com/best-colleges/rankings/computer-science/data-analytics-science) Best Undergraduate Data Science Programs list. Let's say you select 3.\n",
    "- The six numbers you have selected, or  **your numbers**, can be represented all together as (7, 12, 24, 15, 13, 3). This is a _sequence_ of six numbers – **order matters**!\n",
    "\n",
    "The **winning numbers** are chosen by King Triton drawing five balls, one at a time, **without replacement**, from a pot of white balls numbered 1 to 29. Then, he draws a gold ball, the Tritonball, from a pot of gold balls numbered 1 to 8. Both pots are completely separate, hence the different ball colors. For example, maybe the winning numbers are (15, 9, 24, 23, 1, 3).\n",
    "\n",
    "We’ll assume for this problem that in order to win the grand prize (free housing), all six of your numbers need to match the winning numbers and be in the **exact same positions**. In other words, your entire sequence of numbers must be exactly the same as the sequence of winning numbers. However, if some numbers in your sequence match up with the corresponding number in the winning sequence, you will still win some Triton Cash. \n",
    "\n",
    "Suppose again that you select (7, 12, 24, 15, 13, 3) and the winning numbers are (15, 9, 24, 23, 1, 3). In this case, two of your numbers are considered to match two of the winning numbers. \n",
    "- Your numbers: (7, 12, **24**, 15, 13, **3**)\n",
    "- Winning numbers: (15, 9, **24**, 23, 1, **3**)\n",
    "\n",
    "You won't win free housing, but you will win some Triton Cash. Note that although both sequences include the number 15 within the first five numbers (representing a white ball), since they are in different positions, that's not considered a match.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.** Implement a function called `simulate_one_ticket`. It should take no arguments, and it should return an array with 6 random numbers, simulating how the numbers are selected for a single Lucky Triton Lotto ticket. The first five numbers should all be randomly chosen without replacement, from 1 to 29. The last number should be between 1 and 8.\n",
    "\n",
    "***Hint:*** You don't need a `for`-loop for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_one_ticket():\n",
    "    \"\"\"Simulate one Lucky Triton Lotto ticket.\"\"\"\n",
    "    ...\n",
    "simulate_one_ticket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.** It's draw day. You checked the winning numbers King Triton drew, which happened to be **(15, 9, 24, 23, 1, 3)**. Below, calculate how many matches there are between the winning numbers and a randomly generated ticket, and save the result in `num_matches`. Remember, order matters when counting matches!\n",
    "\n",
    "***Hint:*** You don't need a `for`-loop for this question. There is a one-line solution using `np.count_nonzero`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning = np.array([15, 9, 24, 23, 1, 3])\n",
    "simulated_ticket = simulate_one_ticket()\n",
    "num_matches = ...\n",
    "\n",
    "print(f\"The number of matches between the winning numbers {winning} and the simulated ticket {simulated_ticket} is {num_matches}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.** You are disappointed because you bought a lottery ticket but you did not win free housing. To make yourself feel better, you write a simulation to remind yourself how unlikely it is to win the grand prize. \n",
    "\n",
    "Implement a simulation where you call the function `simulate_one_ticket` 100,000 times. In your 100,000 tickets, **how many times did you win the grand prize (free housing)?** Assign your answer to `count_free_housing`. (It would cost a fortune if you were to buy 100,000 tickets – it's pretty nice to be able to simulate this experiment instead of doing it in real life!) \n",
    "\n",
    "***Hint:*** Start by writing a simulation where you only buy 10 tickets. Once you are sure you have that figured out, then ramp it up to 100,000 tickets. This is a good general practice for writing simulations: start small! It may take a little while (up to a minute) for Python to perform the calculations when you are buying 100,000 tickets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning = np.array([15, 9, 24, 23, 1, 3])\n",
    "count_free_housing = ...\n",
    "...\n",
    "count_free_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many times did you win free housing? Remember, the mathematical probability of winning free housing is quite low, on the order of $10^{-9}$. That's a lot lower than 1 in 100,000, which is $10^{-5}$.\n",
    "\n",
    "**Question 1.4.** As we've seen, you would need to be extremely lucky to win the grand prize. To encourage more students to buy Lucky Triton Lotto tickets despite the terrible odds, there are some additional prizes. Students can win Triton Cash if *some* of their numbers match the corresponding winning numbers, as described in the introduction. Again, simulate the act of buying 100,000 tickets, but this time find **the greatest number of matches achieved by any of your tickets**, and assign this number to `most_matches`. \n",
    "\n",
    "For example, if 90,000 of your tickets matched 1 winning number and 10,000 of your tickets matched 2 winning numbers, then you would set `most_matches` to 2. If 99,999 of your tickets matched 1 winning number and one of your tickets matched 4 winning numbers, you would set `most_matches` to 4. If you happened to win the grand prize on one of your tickets, you would set `most_matches` to 6. \n",
    "\n",
    "***Hint:*** There are several ways to approach this; one way involves storing the number of matches per ticket in an array and finding the largest number in that array. Another way involves keeping track of the maximum matches you've encountered so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning = np.array([15, 9, 24, 23, 1, 3])\n",
    "most_matches = ...\n",
    "...\n",
    "most_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5.** Suppose one Lucky Triton Lotto ticket costs $5.\n",
    "\n",
    "The Lucky Triton Lotto advertisement on Instagram promises you will never lose money because of the following generous prizes:\n",
    "\n",
    "- Win $10 with a 1-number match\n",
    "\n",
    "- Win $25 with a 2-number match\n",
    "\n",
    "- Win $100 with a 3-number match\n",
    "\n",
    "- Win $1,000 with a 4-number match\n",
    "\n",
    "- Win $5,000 with a 5-number match\n",
    "\n",
    "- Win $20,000 with a 6-number match (free housing!)\n",
    "\n",
    "If you had the money to buy 100,000 tickets, what would be your net winnings from buying these tickets? Since this is net winnings, this should account for the prizes you win and the cost of buying the tickets. Assign the amount to `net_winnings`. Note that a positive value means you won money overall, and a negative value means you lost money overall. Do you believe the advertisement's claims?\n",
    "\n",
    "The winning numbers are the same from the previous part: **(15, 9, 24, 23, 1, 3)**.\n",
    "\n",
    "***Hint:*** Again, there are a few ways you could approach this problem. One way involves generating another 100,000 random tickets and counting the amount earned per ticket, adding to a running total. Alternatively, if you created an array of the number of matches per ticket in Question 1.4, you could loop through that array. For practice, it's recommended that you try solving this problem multiple ways!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_winnings = ...\n",
    "...\n",
    "net_winnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sampling with Netflix 🍿🎬\n",
    "\n",
    "In this question, we will use a [dataset](https://www.kaggle.com/datasets/luiscorter/netflix-original-films-imdb-scores) consisting of information about **all** Netflix Original movies, including documentaries and specials, that were released before June 1, 2021. We'll treat this data as our population and use it some practice with sampling. Run the cell below to load the data into a DataFrame, indexed by title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, do not change it!\n",
    "movie_data = bpd.read_csv('data/netflix_originals.csv').set_index('Title')\n",
    "movie_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've provided a function called `compute_statistics` that takes as input a DataFrame containing `'Runtime'` and `'IMDb Score'` columns, and then:\n",
    "- draws a histogram of `'Runtime'`,\n",
    "- draws a histogram of `'IMDb Score'`, and\n",
    "- returns a two-element array containing the mean `'Runtime'` and mean `'IMDb Score'`.\n",
    "\n",
    "Run the cell below to define the `compute_statistics` function, and a helper function called `histograms`. Don't worry about how this code works, and please don't change anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell, just run it.\n",
    "def histograms(df):\n",
    "    runtimes = df.get('Runtime').values\n",
    "    ratings = df.get('IMDb Score').values\n",
    "    \n",
    "    plt.subplots(1, 2, figsize=(15, 4), dpi=100)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(runtimes, density=True, alpha=0.5, color='blue', ec='w', bins=np.arange(0, 250, 10))\n",
    "    plt.title('Distribution of Runtimes')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(ratings, density=True, alpha=0.5, color='blue', ec='w', bins=np.arange(0, 10, 0.4))\n",
    "    plt.title('Distribution of IMDb Scores')\n",
    "    \n",
    "def compute_statistics(runtimes_and_ratings_data, draw=True):\n",
    "    if draw:\n",
    "        histograms(runtimes_and_ratings_data)\n",
    "    avg_runtime = runtimes_and_ratings_data.get('Runtime').mean()\n",
    "    avg_rating = runtimes_and_ratings_data.get('IMDb Score').mean()\n",
    "    avg_array = np.array([avg_runtime, avg_rating]) \n",
    "    return avg_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this `compute_statistics` function to show the distribution of `'Runtime'` and `'IMDb Score'` and compute their means, for any collection of movies. \n",
    "\n",
    "Run the next cell to show these distributions and compute the means for all Netflix Original movies. Notice that an array containing the mean `'Runtime'` and mean `'IMDb Score'` values is displayed before the histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_stats = compute_statistics(movie_data)\n",
    "movie_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, imagine that instead of having access to the full *population* of movies, we only have access to data on a smaller subset of movies, or a *sample*.  For 584 movies, it's not so unreasonable to expect to see all the data, but usually we aren't so lucky.  Instead, we often make *statistical inferences* about a large underlying population using a smaller sample.\n",
    "\n",
    "**Statistical inference** is the process of using data in a sample to _infer_ some characteristic about the population from which the sample was drawn. A common strategy for statistical inference is to estimate a parameter of the population by computing a corresponding statistic on a sample. This strategy sometimes works well and sometimes doesn't.  The degree to which it gives us useful answers depends on several factors.\n",
    "\n",
    "One very important factor in the utility of samples is how they were gathered. Let's look at some different sampling strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convenience sampling\n",
    "One sampling methodology, which is **generally a bad idea**, is to choose movies which are somehow convenient to sample.  For example, you might choose movies that you have personally watched, since it's easier to collect information about them.  This is called *convenience sampling*.\n",
    "\n",
    "**Question 2.1.**  Suppose your favorite types of movies are rom-coms 🥰 and thrillers 😱, and you decide to manually look up information on all Netflix Original movies in the following genres:\n",
    "- `'Romantic comedy'`\n",
    "- `'Thriller'`\n",
    "\n",
    "Assign `convenience_sample` to a subset of `movie_data` that contains only the rows for movies that are in one of these two genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convenience_sample = ...\n",
    "convenience_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.** Assign `convenience_stats` to an array of length two, consisting of the mean `'Runtime'` and mean `'IMDb Score'` of your convenience sample.  Since they're computed on a sample, these are called *sample means*. \n",
    "\n",
    "***Hint:*** Use the function `compute_statistics`; it's okay if histograms are displayed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convenience_stats = ...\n",
    "convenience_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll compare the distribution of `'Runtime'` in our convenience sample to the distribution of `'Runtime'` for all the movies in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, do not change it!\n",
    "def compare_runtimes(first, second, first_title, second_title):\n",
    "    \"\"\"Compare the runtimes in two DataFrames.\"\"\"\n",
    "    bins = np.arange(0, 250, 10)\n",
    "    \n",
    "    plt.subplots(1, 2, figsize=(15, 4), dpi=85)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(first.get('Runtime'), bins=bins, density=True, ec='w', color='blue', alpha=0.5)\n",
    "    plt.title(f'Runtimes ({first_title})')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(second.get('Runtime'), bins=bins, density=True, ec='w', color='blue', alpha=0.5)\n",
    "    plt.title(f'Runtimes ({second_title})')\n",
    "\n",
    "compare_runtimes(movie_data, convenience_sample, 'All Movies', 'Convenience Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** From what you see in the histograms above, did the convenience sample give us an accurate picture of the runtimes for the full population of movies?  Why or why not?\n",
    "\n",
    "Assign either 1, 2, 3, or 4 to the variable `sampling_q3` below. \n",
    "1. Yes. The sample is large enough, so it is an accurate representation of the population.\n",
    "1. No. Convenience samples generally don't give us an accurate representation of the population.\n",
    "1. No. Normally convenience samples give us an accurate representation of the population, but we just got unlucky.\n",
    "1. No. Normally convenience samples give us an accurate representation of the population, but only if the sample size is large enough. Our convenience sample here was too small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_q3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple random sampling\n",
    "A more principled approach is to sample uniformly at random from the movies.  If we ensure that each movie is selected at most once, this is a **random sample without replacement**, sometimes called a \"**simple random sample**\" or \"**SRS**\".  Imagine writing down each movie's title on a card, putting the cards in a hat, and shuffling the hat.  To sample, pull out cards one by one and set them aside, stopping when the specified *sample size* is reached.\n",
    "\n",
    "We've produced two simple random samples of `ratings_data`: the variable `small_srs_data` contains a SRS of size 70, and the variable `large_srs_data` contains a SRS of size 180."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll run the same analyses on the small simple random sample, the large simple random sample, and the convenience sample. The subsequent code draws the histograms and computes the means for `'Runtime'` and `'IMDb Score'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell, but do run it.\n",
    "small_srs_data = bpd.read_csv('data/small_srs_rating.csv').set_index('Title')\n",
    "large_srs_data = bpd.read_csv('data/large_srs_rating.csv').set_index('Title')\n",
    "\n",
    "small_stats = compute_statistics(small_srs_data, draw=False);\n",
    "large_stats = compute_statistics(large_srs_data, draw=False);\n",
    "convenience_stats = compute_statistics(convenience_sample, draw=False);\n",
    "\n",
    "print('Full data stats:                 ', movie_stats)\n",
    "print('Small SRS stats:                 ', small_stats)\n",
    "print('Large SRS stats:                 ', large_stats)\n",
    "print('Convenience sample stats:        ', convenience_stats)\n",
    "\n",
    "color_dict = {\n",
    "    'small SRS': 'blue',\n",
    "    'large SRS': 'green',\n",
    "    'convenience sample': 'orange'\n",
    "}\n",
    "\n",
    "plt.subplots(3, 2, figsize=(15, 15), dpi=100)\n",
    "i = 1\n",
    "\n",
    "for df, name in zip([small_srs_data, large_srs_data, convenience_sample], color_dict.keys()):\n",
    "    plt.subplot(3, 2, i)\n",
    "    i += 2\n",
    "    plt.hist(df.get('Runtime'), density=True, alpha=0.5, color=color_dict[name], ec='w', \n",
    "             bins=np.arange(0, 250, 10))\n",
    "    plt.title(f'Runtimes ({name})');\n",
    "\n",
    "i = 2\n",
    "for df, name in zip([small_srs_data, large_srs_data, convenience_sample], color_dict.keys()):\n",
    "    plt.subplot(3, 2, i)\n",
    "    i += 2\n",
    "    plt.hist(df.get('IMDb Score'), density=True, alpha=0.5, color=color_dict[name], ec='w', \n",
    "             bins=np.arange(0, 10, 0.4))\n",
    "    plt.title(f'IMDb Ratings ({name})');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing simple random samples\n",
    "Often it's useful to take random samples even when we have a larger dataset available.  One reason is that doing so can help us understand how inaccurate other samples are.\n",
    "\n",
    "As we saw in [Lecture 13](https://dsc10.com/resources/lectures/lec13/lec13.html#Sampling-rows-from-a-DataFrame), DataFrames have a `.sample` method for producing simple random samples.  Note that its default is to sample **without** replacement, which aligns with how simple random samples are drawn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4.** Produce a simple random sample of size 70 from `movie_data`. Store an array containing the mean `'Runtime'` and mean `'IMDb Score'` of your SRS in `my_small_stats`. Again, it's fine if histograms are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_small_stats = ...\n",
    "my_small_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell above many times, and observe the resulting sample means.\n",
    "\n",
    "<br>\n",
    "\n",
    "Now, recall, `small_stats` is an array containing the mean `'Runtime'` and mean `'IMDb Score'` for the one small SRS that we provided you with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following two-fold question:\n",
    "- Are the values in `my_small_stats` (the mean `'Runtime'` and `'IMDb Score'` for **your** small SRS) similar to the values in `small_stats` (the mean `'Runtime'` and `'IMDb Score'` for the small SRS **we provided you with**)? \n",
    "- Each time you collect a new sample – i.e. each time you re-run the cell where `my_small_stats` is defined – do the values in `my_small_stats` change a lot?\n",
    "\n",
    "Assign either 1, 2, 3, or 4 to the variable `sampling_q4` below.\n",
    "1. The values in `my_small_stats` are identical to the values in `small_stats`, and change a bit each time a new sample is collected.\n",
    "1. The values in `my_small_stats` are identical to the values in `small_stats`, and don't change at all each time a new sample is collected.\n",
    "1. The values in `my_small_stats` are slightly different from the values in `small_stats`, and change a bit each time a new sample is collected.\n",
    "1. The values in `my_small_stats` are very different from the values in `small_stats`, and don't change at all each time a new sample is collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_q4 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5.** Similarly, create a simple random sample of size 180 from `movie_data` and store an array of the sample's mean `'Runtime'` and mean `'IMDb Score'` in `my_large_stats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_large_stats = ...\n",
    "my_large_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell in which `my_large_stats` is defined many times. Do the histograms and  mean statistics (mean `'Runtime'` and mean `'IMDb Score'`) seem to change more or less across samples of size 180 than across samples of size 70?\n",
    "\n",
    "Assign either 1, 2, or 3 to the variable `sampling_q5` below. \n",
    "\n",
    "1. The statistics change *less* across samples of size 180 than across samples of size 70.\n",
    "1. The statistics change an *equal amount* across samples of size 180 and across samples of size 70.\n",
    "1. The statistics change *more* across samples of size 180 than across samples of size 70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_q5 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Milk Tea, Yippee! 🥛🍵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are planning to open a milk tea shop in La Jolla! To get a sense of the local residents' milk tea preferences, you survey 200 randomly selected La Jolla residents and ask which type of tea they prefer the most among six options – `'jasmine'`, `'oolong'`, `'black'`, `'golden'`, `'matcha'`, `'Thai'`. \n",
    "\n",
    "<center><img src=\"images/tea.png\" width=70%></center>\n",
    "\n",
    "Run the next cell to load in the results of the survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = bpd.read_csv('data/tea.csv')\n",
    "survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you're truly interested in, though, is the proportion of *all La Jolla residents* that prefer each type of tea. These are *population parameters* (plural, because there are six proportions).\n",
    "\n",
    "Your friends tell you that matcha tea is popular (it doesn't just taste like grass!) and that your shop should focus on matcha tea-based creations. To make an informed decision, you decide to look at your survey data to determine the proportion of La Jolla residents that prefer `'matcha'` tea over all other types of teas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.** Start by calculating the proportion of residents in your sample who prefer `'matcha'` tea. Assign this value to `matcha_proportion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcha_proportion = ...\n",
    "matcha_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're done... or are you? You have a single estimate for the true proportion of residents who prefer `'matcha'` tea. However, you don't know how close that estimate is, or how much it could have varied if you'd had a different sample. In other words, you have an estimate, but no understanding of how close that estimate is to the true proportion of all local residents who prefer `'matcha'` tea.\n",
    "\n",
    "This is where the idea of resampling via **[bootstrapping](https://inferentialthinking.com/chapters/13/2/Bootstrap.html)** comes in. Assuming that our sample resembles the population fairly well, we can resample from our original sample to produce more samples. From each of these resamples, we can produce another estimate for the true proportion of residents who prefer `'matcha'` tea, which gives us a distribution of sample proportions that describes how the estimate might vary given different samples. We can then use this distribution to understand the **variability** in the estimated proportion of residents who prefer `'matcha'` tea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2.** Now, let's use bootstrapping to get a sense of the distribution of the sample proportion. Complete the following code to produce 1,000 bootstrapped estimates for the proportion of residents who prefer `'matcha'` tea. Store your 1,000 estimates in an array named `boot_matcha_proportions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_matcha_proportions = ...\n",
    "for i in np.arange(1000):\n",
    "    resample = ...\n",
    "    resample_proportion = ...\n",
    "    boot_matcha_proportions = ...\n",
    "boot_matcha_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3.** Using the array `boot_matcha_proportions`, compute an approximate **95%** confidence interval for the true proportion of residents who prefer `'matcha'` tea.  Compute the lower and upper ends of the interval, named `matcha_lower_bound` and `matcha_upper_bound`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcha_lower_bound = ...\n",
    "matcha_upper_bound = ...\n",
    "\n",
    "# Print the confidence interval:\n",
    "print(\"Bootstrapped 95% confidence interval for the true proportion of residents who prefer matcha tea in the population:\\n[{:f}, {:f}]\".format(matcha_lower_bound, matcha_upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4.**\n",
    "Is it true that 95% of the population lies in the range `matcha_lower_bound` to `matcha_upper_bound`? Assign the variable `q3_4` to either `True` or `False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_4 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5.**\n",
    "Is it true that the proportion of La Jolla residents who prefer `'matcha'` tea over the other teas is a random quantity with approximately a 95% chance of falling between `matcha_lower_bound` and `matcha_upper_bound`? Assign the variable `q3_5` to either `True` or `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_5 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6.**\n",
    "Suppose we were somehow able to produce 2,000 new samples, each one a uniform random sample of 200 La Jolla residents taken directly from the population. For each of those 2,000 new samples, we create a 95% confidence interval for the proportion of residents who prefer `'matcha'` tea. Roughly how many of those 2,000 intervals should we expect to actually contain the true proportion of the population? Assign your answer to the variable `how_many` below. It should be of type `int`, representing the *number* of intervals, not the proportion or percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many = ...\n",
    "how_many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.7.** We also created 90%, 96%, and 99% confidence intervals from one sample (shown below), but forgot to label which confidence intervals were which! Match the interval to the percent of confidence the interval represents and assign your choices (either 1, 2, or 3) to variables `ci_90`, `ci_96`, and `ci_99`, corresponding to the 90%, 96%, and 99% confidence intervals respectively.\n",
    "\n",
    "**Hint**: Drawing the confidence intervals out on paper might help you visualize them better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $[0.135, 0.25]$\n",
    "\n",
    "2. $[0.145, 0.24]$\n",
    "\n",
    "3. $[0.12,  0.26]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_90 = ...\n",
    "ci_96 = ...\n",
    "ci_99 = ...\n",
    "ci_90, ci_96, ci_99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.8.** Based on the results in `survey`, it seems that `'jasmine'` tea is more popular than `'matcha'` tea among residents. We would like to construct a range of likely values – that is, a confidence interval – for the difference in popularity, which we define as:\n",
    "\n",
    "$$\\text{(Proportion of residents who prefer jasmine tea)} - \\text{(Proportion of residents who prefer matcha tea)}$$\n",
    "\n",
    "Create a function, `differences_in_resamples`, that:\n",
    "- creates **1000 bootstrapped resamples of the original survey data** in the `survey` DataFrame, \n",
    "- computes the difference in proportions for each resample, and \n",
    "- returns an array of these differences. \n",
    "\n",
    "Then, call your function and store the returned array in a variable called `boot_differences`. \n",
    "\n",
    "Finally, plot a density histogram of these estimates.\n",
    "\n",
    "***Hints:*** \n",
    "- Use your code from Question 3.2 as a starting point.\n",
    "- To plot your histogram, you'll first need to create a DataFrame with one column, whose entries are the values in `boot_differences`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differences_in_resamples():\n",
    "    ...\n",
    "\n",
    "boot_differences = ...\n",
    "\n",
    "# Plot a histogram of boot_differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.9.** Compute an approximate 95% confidence interval for the difference in proportions. Assign the lower and upper bounds of the interval to `diff_lower_bound` and `diff_upper_bound`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_lower_bound = ...\n",
    "diff_upper_bound = ...\n",
    "\n",
    "# Print the confidence interval:\n",
    "print(\"Bootstrapped 95% confidence interval for the difference in popularity between jasmine tea and matcha tea:\\n[{:f}, {:f}]\".format(diff_lower_bound, diff_upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.10.** In this question, you computed two 95% confidence intervals:\n",
    "- In Question 3.3, you found a 95% confidence interval for the proportion of residents who prefer `'matcha'` tea among the six tea options. Let's call this the \"matcha CI.\"\n",
    "- In Question 3.9, you found a 95% confidence interval for the difference between the proportion of residents who prefer `'jasmine'` tea and the proportion of residents who prefer `'matcha'` tea. Let's call this the \"difference CI.\" \n",
    "\n",
    "Choose how to best fill in the blanks to describe the widths of these two confidence intervals. Set `q3_10` to either 1, 2, 3, or 4.\n",
    "\n",
    ">The matcha CI is ________________________ than the difference CI because we have a ________________________ for a single unknown parameter than the difference between two unknown parameters.\n",
    "\n",
    "1. wider; more accurate guess\n",
    "1. narrower; more accurate guess\n",
    "1. wider; less accurate guess\n",
    "1. narrower; less accurate guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_10 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. BTS Comeback 🎤🤩\n",
    "\n",
    "BTS, a popular South Korean boy band, has been on hiatus as its members took time to complete their mandatory military service. Recently, however, the group has reassembled and announced that they'll be [releasing a new album and going a world tour](https://www.teenvogue.com/story/bts-2026-comeback-tour-everything-you-need-to-know) in spring of 2026. The tour dates have not been announced yet, but some fans are speculating possible performances at these 4 cities in Asia:\n",
    "\n",
    "- Seoul, South Korea\n",
    "- Tokyo, Japan\n",
    "- Bangkok, Thailand\n",
    "- Singapore, Singapore\n",
    "\n",
    "\n",
    "You and your friends want to plan a trip to Asia to see BTS. Since you have a limited budget and will already spend a lot of money on the concert tickets, you want to stay in the city which has the cheapest hotels. You gathered hotel data from [Expedia](https://www.expedia.com/) for the four cities above. The `hotels` DataFrame contains a **sample** of all the hotels in the four cities above. Each row corresponds to a particular hotel, and the columns give us information about the `'Hotel Name'`, the `'City'`, the `'Price'` in USD for one night, and the `'Customer Rating'` from 1-10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels = bpd.read_csv('data/hotels.csv')\n",
    "hotels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1.** Let's start by determining the mean hotel price for each city. Create a DataFrame called `city_means`, indexed by `'City'`, with one column called `'Price'` that contains the mean hotel price for that city. Sort `city_means` in descending order of `'Price'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_means = ...\n",
    "city_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2.** Based on the data we have, Singapore on average has the most expensive hotels. However, our data is only a sample of all the hotels in the 4 cities, and the mean hotel price we computed for Singapore is only a sample statistic, not a population parameter. \n",
    "\n",
    "Produce 1,000 bootstrapped estimates for the mean price of **all** hotels in Singapore. Store the estimates in the `sg_hotel_means` array. Then, use the `sg_hotel_means` array to calculate an approximate **99% confidence interval** for the true mean price of all hotels in Singapore. Assign the endpoints of your interval to `lower_bound` and `upper_bound`.\n",
    "\n",
    "***Hint:*** Make sure to query **before** resampling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_hotel_means = ...\n",
    "\n",
    "\n",
    "lower_bound = ...\n",
    "upper_bound = ...\n",
    "\n",
    "# Display the estimates in a histogram.\n",
    "bpd.DataFrame().assign(Estimated_Average_Price=sg_hotel_means).plot(kind='hist', density=True, ec='w', figsize=(10, 5), title=\"Singapore\");\n",
    "plt.plot([lower_bound, upper_bound], [0, 0], color='gold', linewidth=10, label='99% confidence interval');\n",
    "\n",
    "# Don't change what's below (though you will need to copy and change it in 4.3).\n",
    "city_name = 'Singapore'\n",
    "f'A 99% confidence interval for the average hotel price in {city_name} is [{lower_bound}, {upper_bound}].'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3.** Now we want to create a similar histogram for the other 3 cities. Instead of copying our code from Question 4.2 and changing it to work for each city, let's write a more general function that works for _any_ city we choose. \n",
    "\n",
    "Create a function called `city_and_hist`, which takes in a city name as a string, and:\n",
    "1. **Plots the histogram** of 1,000 bootstrapped estimates for the city's mean hotel price.\n",
    "2. **Returns** a string describing the approximate 99% confidence interval for the city's mean hotel price, formatted in the same way as the string displayed for Singapore in Question 4.2.\n",
    "\n",
    "***Notes:*** \n",
    "- Make sure your function both plots a histogram and **returns** a string. For example, `city_and_hist('Tokyo')` should return a string that starts with `'A 99% confidence interval for the average hotel price in ... is'` where ... is the city name.\n",
    "- The string displayed at the end of Question 4.2. was created using a feature of Python called f-strings. You'll need to copy and change that f-string expression. Read [this article](https://realpython.com/python-f-strings/#simple-syntax) for more details about f-strings if you're interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def city_and_hist(city_name):\n",
    "    ...\n",
    "    \n",
    "# Example calls to the function. Don't change the lines below.\n",
    "tokyo_string = city_and_hist('Tokyo')\n",
    "print(tokyo_string)\n",
    "seoul_string = city_and_hist('Seoul')\n",
    "print(seoul_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish Line: Almost there, but make sure to follow the steps below to submit! 🏁\n",
    "\n",
    "**_Citations:_** Did you use any generative artificial intelligence tools to assist you on this assignment? If so, please state, for each tool you used, the name of the tool (ex. ChatGPT) and the problem(s) in this assignment where you used the tool for help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">\n",
    "\n",
    "Please cite tools here.\n",
    "\n",
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To submit your assignment:\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "2. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "3. Run the cell below to run all tests, and make sure that they all pass.\n",
    "4. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope.\n",
    "5. Stick around while the Gradescope autograder grades your work. Make sure you see that all tests have passed on Gradescope.\n",
    "6. Check that you have a confirmation email from Gradescope and save it as proof of your submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
