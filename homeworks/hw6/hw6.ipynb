{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6: Hypothesis Testing and Permutation Testing\n",
    "\n",
    "## Due Tuesday, November 25th at 11:59PM\n",
    "\n",
    "Welcome to Homework 6, the last homework of the quarter! This homework covers hypothesis testing ([CIT 11](https://inferentialthinking.com/chapters/11/Testing_Hypotheses.html)) and permutation testing ([CIT 12](https://inferentialthinking.com/chapters/12/Comparing_Two_Samples.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "You are given six slip days throughout the quarter to extend deadlines. See the syllabus for more details. With the exception of using slip days, late work will not be accepted unless you have made special arrangements with your instructor.\n",
    "\n",
    "**Important**: For homeworks, the `otter` tests don't usually tell you that your answer is correct. More often, they help catch careless mistakes. It's up to you to ensure that your answer is correct. If you're not sure, ask someone (not for the answer, but for some guidance about your approach). These are great questions for office hours (see the schedule on the [Calendar](https://dsc10.com/calendar)) or Campuswire. Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell, but do make sure to run it\n",
    "import babypandas as bpd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-colorblind')\n",
    "\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Secret Smiski üßç\n",
    "\n",
    "<center><img src='images/smiskis.png' width='600'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smiskis are tiny glow-in-the-dark collectible figurines. Each Smiski is packaged in an identical box so that you don't know which Smiski you have when you pick up a box. Due to this packaging, it isn't easy to get a specific Smiski, but it's even rarer to get a special type of Smiski called a *secret* Smiski. Although no one knows the exact probability of obtaining a secret Smiski, you [read online](https://www.reddit.com/r/smiskis/comments/15myvll/how_rare_are_secret_smiskis_really/) that chance of obtaining a secret Smiski is $\\frac{1}{144}$. \n",
    "\n",
    "Many of the DSC 10 tutors are avid Smiski collectors and have collectively bought 903 Smiskis over the past few years. Out of all the Smiskis they collected, they got 10 secret Smiskis. Due to this outcome, the tutors suspect the probability of getting a secret Smiski should be higher than $\\frac{1}{144}$.\n",
    "\n",
    "To test this, they decide to run a hypothesis test with the following hypotheses:\n",
    "\n",
    "**Null Hypothesis**: The probability of obtaining a secret Smiski is $\\frac{1}{144}$. \n",
    "\n",
    "**Alternative Hypothesis**: The probability of obtaining a secret Smiski is greater than $\\frac{1}{144}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.** Complete the implementation of the function `one_simulation`, which has no arguments. It should randomly generate 903 Smiskis under the assumptions of the null hypothesis and return the **proportion** of Smiskis that are secret Smiskis. \n",
    "\n",
    "***Hint:*** Use `np.random.multinomial`. You don't need a `for`-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_simulation():\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test statistic for our hypothesis test will be the difference between the proportion of secret Smiskis obtained in a given sample of 903 Smiskis and the expected proportion of secret Smiskis. \n",
    "\n",
    "$$\\text{test statistic} = \\text{proportion of secret Smiskis in sample} - \\frac{1}{144}$$\n",
    "\n",
    "**Question 1.2.** Calculate the observed value of the test statistic and store the result in `smiski_observed`. Recall that the DSC 10 tutors have 903 Smiskis, 10 of which are secret Smiskis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiski_observed = ...\n",
    "smiski_observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.** Let's conduct 10,000 simulations. Create an array named `proportion_diffs` containing 10,000 simulated values of the test statistic described above. Make use of your `one_simulation` function from Question 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_diffs = ...\n",
    "\n",
    "# Visualize with a histogram. Don't change anything below.\n",
    "bpd.DataFrame().assign(proportion_differences=proportion_diffs).plot(kind='hist', bins=15, density=True, ec='w', figsize=(10, 5));\n",
    "plt.axvline(x=smiski_observed, color='black', linewidth=4, label='observed statistic')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4.** Calculate the p-value for this hypothesis test, and assign the result to `smiski_p`.\n",
    "\n",
    "***Hint:*** Do large values of our test statistic favor the alternative hypothesis, or do small values of our test statistic favor the alternative hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiski_p = ...\n",
    "smiski_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5.** Using the standard p-value cutoff of 0.05, what can we conclude from our hypothesis test? Assign either 1, 2, 3, or 4 to the variable `smiski_conclusion`, corresponding to the best conclusion.\n",
    "\n",
    "   1. We reject the null hypothesis. There is not enough evidence to draw a conclusion about whether the data is consistent with the model.\n",
    "   1. We reject the null hypothesis. The observed data is inconsistent with the model.\n",
    "   1. We accept the null hypothesis. The observed data is consistent with the model.\n",
    "   1. We fail to reject the null hypothesis. There is not enough evidence to say that the observed data is inconsistent with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiski_conclusion = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.6.** In this question, we chose as our test statistic the proportion of secret Smiskis obtained minus $\\frac{1}{144}$. But this is not the only statistic we could have chosen; there are many that could have worked here. \n",
    "\n",
    "From the options below, choose the test statistics that would **not** have worked for this hypothesis test, and assign the variable `bad_choices` to a list of your choices.\n",
    "\n",
    "1. The number of secret Smiskis obtained out of 903 Smiskis.\n",
    "1. The absolute difference between 10 and the number of secret Smiskis obtained.\n",
    "1. The absolute difference between $\\frac{1}{144}$ and the proportion of secret Smiskis obtained.\n",
    "1. $\\frac{1}{144}$ minus the proportion of secret Smiskis obtained.\n",
    "1. The proportion of secret Smiskis obtained.\n",
    "\n",
    "***Hint:*** Our goal is to find a test statistic that will help us determine whether we got secret Smiskis **more** often than expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_choices = ...\n",
    "bad_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gotta Catch 'Em All ‚úÖ\n",
    "\n",
    "<center><img src='./images/pokemon.jpg' width='400'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pok√©mon Trading Card Game Pocket (TCGP)](https://tcgpocket.pokemon.com/en-us/) is a mobile adaptation of the classic Pok√©mon trading card game. Players build decks using cards that feature different Pok√©mon (short for Pocket Monsters). \n",
    "\n",
    "There are different tiers for Pok√©mon cards, representing their rarity. Diamonds are used for the common cards, with one diamond being the most common. Cards with a star are more rare, and finally, crowns represent the rarest cards. \n",
    "\n",
    "Bill is a DSC 10 tutor who has been playing TCGP for a while. He wonders how cards are distributed across the different rarity tiers. Based on his extensive gameplay, he proposes the following probability distribution for how frequently each type of card appears. Note that the sum of the estimated probabilities is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Rarity Tier | Bill's Estimated Probability|\n",
    "| --- | --- |\n",
    "| One Diamond | $0.25$ |\n",
    "| Two Diamonds | $0.2$ |\n",
    "| Three Diamonds | $0.15$ |\n",
    "| Four Diamonds | $0.1$ |\n",
    "| One Star| $0.09$ |\n",
    "| Two Stars | $0.08$ |\n",
    "| Three Stars| $0.07$ |\n",
    "| Crown |$0.06$|\n",
    "\n",
    "We'll store this **proposed** distribution in an array, in the order shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, do not change it!\n",
    "proposed_dist = np.array([0.25, 0.2, 0.15, 0.1, 0.09, 0.08, 0.07, 0.06])\n",
    "proposed_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the validity of Bill's model, you collect data directly from Pok√©mon TCGP. You learn that the last 1,000 cards were as follows:\n",
    "\n",
    "| Rarity Tier | Number of Cards|\n",
    "| --- | --- |\n",
    "| One Diamond | $264$ |\n",
    "| Two Diamonds | $224$ |\n",
    "| Three Diamonds | $154$ |\n",
    "| Four Diamonds | $105$ |\n",
    "| One Star| $88$ |\n",
    "| Two Stars | $68$ |\n",
    "| Three Stars| $62$ |\n",
    "| Crown |$35$|\n",
    "\n",
    "You then calculate the **observed** distribution using the data you collected and store it in an array as well (in the same order as before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, do not change it!\n",
    "observed_dist = np.array([264, 224, 154, 105, 88, 68, 62, 35]) / 1000\n",
    "observed_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `observed_dist` is not identical to `proposed_dist`, it's still possible that Bill's model is plausible, and that the differences are simply due to random chance. Let's run a hypothesis test to investigate further, using the following hypotheses: \n",
    "\n",
    "- **Null Hypothesis**: Pok√©mon TCGP Cards are randomly drawn from the distribution `proposed_dist`.\n",
    "\n",
    "- **Alternative Hypothesis**: Pok√©mon TCGP Cards are _not_ drawn randomly from the distribution `proposed_dist`.\n",
    "\n",
    "Note that this hypothesis test involves eight proportions, one for each rarity tier.\n",
    "\n",
    "**Question 2.1.**  Which of the following is **not** a reasonable choice of test statistic for this hypothesis test? Assign 1, 2, or 3 to the variable `unreasonable_test_statistic`. \n",
    "1. The sum of the absolute differences between the proposed distribution (Bill's expected proportion of rarities) and the observed distribution (actual proportion of rarities).\n",
    "1. The absolute difference between the sum of the proposed distribution (Bill's expected proportion of rarities) and the sum of the observed distribution (actual proportion of rarities).\n",
    "1. Among all eight card rarities, the largest absolute difference between Bill's expected proportion and the actual proportion of cards of that rarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unreasonable_test_statistic = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.** We'll use the TVD, i.e. **total variation distance**, as our test statistic. Below, complete the implementation of the function `total_variation_distance`, which takes as input two distributions (stored as arrays) and returns the total variation distance between those distributions.\n",
    "\n",
    "Then, use the function `total_variation_distance` to determine the TVD between the distribution proposed by Bill and the observed distribution of rarities. Assign this TVD to `observed_tvd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variation_distance(first_distrib, second_distrib):\n",
    "    '''Computes the total variation distance between two distributions.'''\n",
    "    ...\n",
    "\n",
    "observed_tvd = ...\n",
    "observed_tvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** Now, we'll calculate 5,000 simulated TVDs to see what a typical TVD between the proposed distribution and a simulated distribution would look like if Bill's model were accurate. Since our real-life data includes 1000 cards, in each trial of the simulation, we'll:\n",
    "- draw 1000 cards at random from Bill's proposed distribution, then \n",
    "- calculate the TVD between **Bill's proposed type distribution** and the **type distribution from the simulated sample**. \n",
    "\n",
    "Store these 5,000 simulated TVDs in an array called `simulated_tvds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_tvds = ...\n",
    "\n",
    "# Visualize the distribution of TVDs with a histogram\n",
    "bpd.DataFrame().assign(simulated_tvds=simulated_tvds).plot(kind='hist', density=True, ec='w', figsize=(10, 5));\n",
    "plt.axvline(x=observed_tvd, color='black', linewidth=4, label='observed TVD')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4.** Now, determine the p-value for our test by finding the proportion of times in our simulation that we saw a TVD greater than or equal to our observed TVD. Assign your result to `pokemon_p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_p = ...\n",
    "pokemon_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5.** Using a p-value cutoff of 0.01, what can we conclude from our hypothesis test? Assign either 1, 2, 3, or 4 to the variable `pokemon_conclusion`, corresponding to the best conclusion.\n",
    "   \n",
    "   1. We accept the null hypothesis. The observed data is consistent with the model.\n",
    "   1. We reject the null hypothesis. There is not enough evidence to say that the observed data is consistent with the model.\n",
    "   1. We reject the null hypothesis. The observed data is inconsistent with the model.\n",
    "   1. We fail to reject the null hypothesis. There is not enough evidence to say that the observed data is inconsistent with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_conclusion = ...\n",
    "pokemon_conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Python vs Java üêç‚òï"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Stack Overflow](https://stackoverflow.com/) is an online forum where users can ask and answer questions about code. (If you've never used it before, it is a great resource!)\n",
    "\n",
    "In this section, we'll work with a dataset of Stack Overflow questions from 2016 to 2020, downloaded from [Kaggle](https://www.kaggle.com/datasets/imoore/60k-stack-overflow-questions-with-quality-rate?resource=download&select=train.csv). The data has been cleaned and condensed for the purposes of this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains six columns: `'Id'`, `'Title'`, `'Body'`, `'Tags'`, `'CreationDate'`, `'Rating'`. Let's read it in and store it as a DataFrame named `stack_overflow`.\n",
    "\n",
    "| Column | Description |\n",
    "| --- | --- |\n",
    "| `'Id'` | ID of the question |\n",
    "| `'Title'` | Title of the question |\n",
    "| `'Body'` | Description of the question |\n",
    "| `'Tags'` | Tags used to categorize question |\n",
    "| `'CreationDate'` | Date the question was asked |\n",
    "| `'Rating'` | Quality rating of the post |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_overflow = bpd.read_csv('data/stack_overflow.csv')\n",
    "stack_overflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.**\n",
    "Each post is given a quality rating. **We're interested in exploring whether Python posts have higher ratings than Java posts.**\n",
    "\n",
    "To determine whether a post is about Python or Java, we can look in the `'Tags'` column. The values in the `'Tags'` column contain several tags that are used to categorize posts. One of the tags for each post will be the programming language the post is about ‚Äì for instance, in the third row shown above, one of the tags for the post is `'<python>'`.\n",
    "\n",
    "Below, assign `python_java` to a DataFrame that only contains questions that used the tags `'<python>'` or `'<java>'`. Don't worry about capitalization as all the tags have already been lowercased. Note that these questions may include other tags as well. \n",
    "\n",
    "***Hints:*** \n",
    "- Use [`str.contains`](https://dsc-courses.github.io/bpd-reference/docs/documentation/series-methods/ser.str.contains()).\n",
    "- There is a `'<javascript>'` tag, but that's not the same as the `'<java>'` tag, as JavaScript and Java are different programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_java = ...\n",
    "python_java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon further investigation, it looks like there are some posts that contain both the tags `'<python>'` and `'<java>'`. For the purposes of answering our question, we only want posts that have `'<python>'` or `'<java>'`, but not both. We've gone ahead and removed the posts that contained both tags and saved the resulting DataFrame to `fixed_python_java`, which you should use in Question 3.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it.\n",
    "fixed_python_java = python_java[(python_java.get('Tags').str.contains('<python>')) & (python_java.get('Tags').str.contains('<java>')) == False]\n",
    "fixed_python_java"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2.** As we have seen, posts can be associated with multiple tags, but the only piece of information in the `'Tags'` column we're interested in is whether the language of the post is Python or Java.\n",
    "\n",
    "Complete the implementation of the function `simplify_tag`, which takes in a string of tags associated with a single post and returns either `'Python'` or `'Java'`. \n",
    "\n",
    "Once you've done that, use your function to help you create a new DataFrame named `with_language` that has all the same columns as `fixed_python_java`, in the same order, with an additional column named `'Language'` that contains the programming language associated with the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_tag(tag): \n",
    "    ...\n",
    "    \n",
    "with_language = ...\n",
    "with_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3.** As a reminder, we're interested in exploring whether Python posts have higher ratings than Java posts. In order to do that, we need to have ratings in the form of numbers, but right now, the `'Rating'` column contains categorical values. The [data source](https://www.kaggle.com/datasets/imoore/60k-stack-overflow-questions-with-quality-rate?resource=download&select=train.csv) describes these values as follows: \n",
    "\n",
    "- `'HQ'`: High-quality posts without a single edit.\n",
    "- `'LQ_EDIT'`: Low-quality posts with a negative score, and multiple community edits. However, they still remain open after those changes.\n",
    "- `'LQ_CLOSE'`: Low-quality posts that were closed by the community without a single edit.\n",
    "\n",
    "We're going to assign a numerical rating of `1` to low-quality posts that were closed (`'LQ_CLOSE'`), `2` to low-quality posts that remained open after edits ( `'LQ_EDIT'`) and `3` to high-quality posts (`'HQ'`).\n",
    "\n",
    "Complete the implementation of the function `numerical_rating`, which takes in a **string** from the `'Rating'` column and returns the corresponding numerical rating as described above. Once you've implemented `numerical_rating`, use it to **replace** the values in the `'Rating'` column of `with_language` with the corresponding numerical ratings.\n",
    "\n",
    "***Note:*** Our implementation of `numerical_rating` used only two lines of code, and one of the lines involved defining a dictionary. You don't have to use a dictionary in your implementation, but doing so will help keep your code concise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_rating(rating):\n",
    "    ...\n",
    "\n",
    "with_language = ...\n",
    "with_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4.** Using the DataFrame `with_language`, calculate the difference between the **mean** `'Rating'` of Python posts and Java posts. Assign your answer to `observed_difference`.\n",
    "\n",
    "$$\\text{observed difference} = \\text{mean Python post rating} - \\text{mean Java post rating}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_difference = ...\n",
    "observed_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now we want to conduct a permutation test to see if it is by chance that the average rating for Python posts is higher than the average rating of Java posts in our sample, or if Python posts actually have a higher rating on average than Java posts.\n",
    "\n",
    "- **Null Hypothesis**: The ratings of Python posts and Java posts come from the same distribution.  \n",
    "- **Alternative Hypothesis**: The ratings of Python posts are higher on average than the ratings of Java posts.\n",
    "\n",
    "**Question 3.5.** Assign `language_rating` to a DataFrame with only two columns, `'Language'` and `'Rating'`, since these are the only relevant columns in `with_language` for this permutation test.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_5\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_rating = ...\n",
    "language_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6.** To perform the permutation test, do the following 1000 times:\n",
    "1. Shuffle the `'Language'` column  of `language_rating`. This permutation of labels groups the rows into two random groups (the rows assigned Python and the rows assigned Java).\n",
    "2. Compute the difference in mean rating between the Python group and the Java group (in the order Python minus Java).\n",
    "3. Append your result to the `differences` array.\n",
    "\n",
    "In the end, the `differences` array should contain 1000 values, each representing the difference in mean rating between two randomly determined groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = ...\n",
    "\n",
    "# Just display the first ten differences.\n",
    "differences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.7.** Compute a p-value for this hypothesis test and assign your answer to `stack_overflow_p`. To decide whether to use `<=` or `>=` in the calculation of the p-value, think about whether larger values or smaller values of our test statistic favor the alternative hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_overflow_p = ...\n",
    "stack_overflow_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.8.** Assign the variable `stack_overflow_conclusion` to a **list** of all the true statements below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We accept the null hypothesis at the 0.01 significance level.\n",
    "1. We reject the null hypothesis at the 0.01 significance level.\n",
    "1. We fail to reject the null hypothesis at the 0.01 significance level.\n",
    "1. We accept the null hypothesis at the 0.05 significance level.\n",
    "1. We reject the null hypothesis at the 0.05 significance level.\n",
    "1. We fail to reject the null hypothesis at the 0.05 significance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_overflow_conclusion = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.9.** Suppose in this question you had shuffled the `'Rating'` column instead and kept the `'Language'` column in the same order. Assign `shuffled_rating` to either 1, 2, 3, or 4, corresponding to the true statement below.\n",
    "\n",
    "\n",
    "1. The new p-value from shuffling `'Rating'` would be $1 - p$, where $p$ is the old p-value from shuffling `'Language'` (i.e. your answer to Question 3.7).\n",
    "1. We would need to change our null hypothesis in order to shuffle the `'Rating'` column. \n",
    "1. There would be no difference in the conclusion of the test if we had shuffled the `'Rating'` column instead.\n",
    "1. The `'Rating'` column cannot be shuffled because it contains numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_rating = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.10.** Which of the following choices best describes the purpose of shuffling one of the columns in our dataset in a permutation test? Assign `why_shuffle` to either 1, 2, 3, or 4, corresponding to the true statement below.\n",
    "\n",
    "1. Shuffling mitigates noise in our data by generating new permutations of the data.\n",
    "1. Shuffling is a special case of bootstrapping and allows us to produce an interval of estimates for an unknown parameter.\n",
    "1. Shuffling allows us to generate new data under the null hypothesis, which helps us determine if our observed data is consistent with the null hypothesis.\n",
    "1. Shuffling allows us to generate new data under the alternative hypothesis, which explains that the data come from different distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "why_shuffle = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Battery Life üîãüéß"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You and your friend are studying together for your DSC 10 final exam. Since both of you focus better when listening to music, you  challenge yourselves to study uninterrupted until each of your earbuds run out of battery. You own a pair of _Apple AirPods_ (i.e., AirPods) and your friend owns a pair of _Samsung Galaxy Buds Pro_ (i.e., Galaxy Buds). You both put on your earbuds and get to work.\n",
    "\n",
    "At the end of the study session, you find that your AirPods, which were fully charged at the start, lasted 4 hours and 18 minutes, while your friend's Galaxy Buds, also fully charged at the start, lasted 4 hours and 41 minutes. Intrigued by the noticeable difference in battery life between the two earbuds, you decide to investigate further. You make a post on Reddit asking people who have AirPods or Galaxy Buds to record how long their earbuds last on a single charge. You're overwhelmed by the amazing response and receive 80 different comments in total from other people, 40 from people with AirPods and 40 from people with Galaxy Buds.\n",
    "\n",
    "Let's look at all the data that you crowdsourced. Each entry in the `'BatteryLife'` column represents the amount of time that a pair of earbuds lasted on a full charge, in minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battery_life_data = bpd.read_csv('data/earbuds.csv')\n",
    "battery_life_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1.** Now let's address the question: how does the average battery life of Galaxy Buds compare to that of AirPods? Create a DataFrame called `galaxy` that contains only the battery life data for Galaxy Buds, and set `galaxy_mean` to the mean battery life of Galaxy Buds. Similarly, create a DataFrame `airpods` for AirPods and compute `airpods_mean`. Finally, set `observed_diff_mean`, to the difference in mean battery life of Galaxy Buds and AirPods in our sample, computed as follows.\n",
    "\n",
    "$$\\text{difference} = \\text{mean battery life of Galaxy Buds} - \\text{mean battery life of AirPods}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy = ...\n",
    "airpods = ...\n",
    "galaxy_mean = ...\n",
    "airpods_mean = ...\n",
    "observed_diff_mean = ...\n",
    "observed_diff_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you answered Question 4.1 correctly, you should have noticed a difference in the average battery life between Galaxy Buds and AirPods. But remember, we are only analyzing samples of size 40 for each brand. Would we observe such a difference in battery life if we had access to the entire population ‚Äì that is, all units ever produced by both brands ‚Äì or is it possible that this difference is merely a result of the specific samples we happened to collect? Let's do a **hypothesis test** to find out. We'll state our hypotheses as follows:\n",
    "\n",
    "- **Null Hypothesis**: The average battery life of Galaxy Buds is equal to that of AirPods. In other words, the difference in average battery life between the two brands equals 0 minutes.\n",
    "\n",
    "- **Alternative Hypothesis**: The average battery life of Galaxy Buds is not equal to that of AirPods. Hence, the difference in average battery life between the two brands is not 0 minutes.\n",
    "\n",
    "\n",
    "Since we are able to frame our hypothesis test as a question of whether a certain population parameter ‚Äì the difference in average battery life between Galaxy Buds and AirPods ‚Äì is equal to a specific value, we can **test our hypotheses by constructing a confidence interval** for this parameter. For a refresher on this method, refer to [CIT 13.4](https://inferentialthinking.com/chapters/13/4/Using_Confidence_Intervals.html) or the human body temperature example from [Lecture 21](https://dsc10.com/resources/lectures/lec21/lec21.html).\n",
    "\n",
    "***Note:*** We are **not** conducting a permutation test here, although that would also be a valid approach to test these hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2.** Compute 1000 **bootstrapped estimates** for the difference in average battery life between Galaxy Buds and AirPods. As in Question 4.1, calculate the difference as Galaxy Buds minus AirPods. Store your 1000 estimates in the `difference_means` array.\n",
    "\n",
    "You should generate your Galaxy Buds resamples by sampling from `galaxy`, and your AirPods resamples by sampling from `airpods`. Do not use the combined dataset `battery_life_data` for this task, otherwise you might not wind up with 40 of each!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_means = ...\n",
    "\n",
    "# Just display the first ten differences.\n",
    "difference_means[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize your estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd.DataFrame().assign(BootstrappedDifferenceMeans = difference_means).plot(kind = 'hist', density=True, ec='w', bins=20, figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3.** Compute a 95% confidence interval for the difference in mean battery life of AirPods and Galaxy Buds (as before, in the order Galaxy Buds minus AirPods). Assign the left and right endpoints of this confidence interval to `left_endpoint` and `right_endpoint` respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_endpoint = ...\n",
    "right_endpoint = ...\n",
    "\n",
    "print('Bootstrapped 95% confidence interval for the mean difference in battery life of AirPods and Galaxy Buds:\\n [{:f}, {:f}]'.format(left_endpoint, right_endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4.** Based on the confidence interval you've created, would you reject the null hypothesis at the 0.05 significance level? Set `reject_null` to True if you would reject the null hypothesis, and False if you would not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_null = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.5.** What if all the people who responded to your original Reddit post had provided their battery lives in hours instead of minutes? Would your hypothesis test still come to the same conclusion either way? Set `same_conclusion` to True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_conclusion = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish Line: Almost there, but make sure to follow the steps below to submit! üèÅ\n",
    "\n",
    "**_Citations:_** Did you use any generative artificial intelligence tools to assist you on this assignment? If so, please state, for each tool you used, the name of the tool (ex. ChatGPT) and the problem(s) in this assignment where you used the tool for help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">\n",
    "\n",
    "Please cite tools here.\n",
    "\n",
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You are done with Homework 6 ‚Äì the final homework of the quarter! üéâ\n",
    "\n",
    "To submit your assignment:\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "1. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "1. Run the cell below to run all tests, and make sure that they all pass.\n",
    "1. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope.\n",
    "1. Stick around while the Gradescope autograder grades your work. Make sure you see that all tests have passed on Gradescope.\n",
    "1. Check that you have a confirmation email from Gradescope and save it as proof of your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
